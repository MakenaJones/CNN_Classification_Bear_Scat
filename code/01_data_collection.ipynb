{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Data Collection\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I use code from [source](https://python.plainenglish.io/how-to-automatically-download-bulk-images-for-your-dataset-using-python-f1efffba7a03) to download pictures for my data set. I start by scraping google images using different search terms related to bear droppings, as well as search terms related to different animals, such as fox, horse, cougar, dogs (ie. animals you would find on a hiking trail). \n",
    "\n",
    "I gathered the top 80 images for each term, and then manually sorted them into the two folders : \"bear scat\" and \"not bear scat\", until I had 524 images in each folder, for a total of 1048 images in my data set. I had to manually sort as some of the photos pulled from google under \"bear poop\" were not all actually photos of feces. \n",
    "\n",
    "The sorted photos are found in the ['images'](https://git.generalassemb.ly/makenajones/Capstone/tree/main/images) folder of this repository and are used for the models in the following sections.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UvDCS11V2o2J"
   },
   "outputs": [],
   "source": [
    "# Import Libraries.\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "aAl4XNqo3iGZ"
   },
   "outputs": [],
   "source": [
    "# Set google variables.\n",
    "google_image = \"https://www.google.com/search?site=&tbm=isch&source=hp&biw=1873&bih=990&\"\n",
    "\n",
    "user_agent = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code directly from [source](https://python.plainenglish.io/how-to-automatically-download-bulk-images-for-your-dataset-using-python-f1efffba7a03)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "zrW8-e1Z333f"
   },
   "outputs": [],
   "source": [
    "# Build the main function for saving downloaded images.\n",
    "saved_folder = 'images_raw'\n",
    "\n",
    "def main(search):\n",
    "    if not os.path.exists(saved_folder):\n",
    "        os.mkdir(saved_folder)\n",
    "    download_images(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code directly from [source]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the download function.\n",
    "def download_images(search):\n",
    "    data = search\n",
    "\n",
    "    print('searching...')\n",
    "\n",
    "    search_url = google_image + 'q=' + data\n",
    "\n",
    "    response = requests.get(search_url, headers=user_agent)\n",
    "\n",
    "    html = response.text\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    results = soup.findAll('img', {'class': 'rg_i Q4LuWd'})\n",
    "\n",
    "    count = 1\n",
    "    links = []\n",
    "    for result in results:\n",
    "        try:\n",
    "            link = result['data-src']\n",
    "            links.append(link)\n",
    "            count += 1\n",
    "            if(count > 80):\n",
    "                break\n",
    "\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    print(f\"Downloading {len(links)} images...\")\n",
    "\n",
    "    for i, link in enumerate(links):\n",
    "        response = requests.get(link)\n",
    "\n",
    "        image_name = saved_folder + '/' + data + str(i+1) + '.jpg'\n",
    "\n",
    "        with open(image_name, 'wb') as fh:\n",
    "            fh.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code modified from [source](https://python.plainenglish.io/how-to-automatically-download-bulk-images-for-your-dataset-using-python-f1efffba7a03)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of terms to search.\n",
    "searches = ['bear poo', \n",
    "            'bear scat', \n",
    "            'grizzly bear scat',\n",
    "            'black bear scat',\n",
    "            'brown bear scat', \n",
    "            'grizzly bear poo', \n",
    "            'black bear poo', \n",
    "            'bear droppings identification', \n",
    "            'bear feces',\n",
    "            'dog poo',\n",
    "            'horse poo'\n",
    "            'cat poo',\n",
    "            'cougar scat',\n",
    "            'cougar poo',\n",
    "            'grass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching...\n",
      "Downloading 80 images...\n",
      "searching...\n",
      "Downloading 80 images...\n",
      "searching...\n",
      "Downloading 80 images...\n",
      "searching...\n",
      "Downloading 80 images...\n",
      "searching...\n",
      "Downloading 80 images...\n",
      "searching...\n",
      "Downloading 80 images...\n",
      "searching...\n",
      "Downloading 80 images...\n",
      "searching...\n",
      "Downloading 80 images...\n",
      "searching...\n",
      "Downloading 80 images...\n",
      "searching...\n",
      "Downloading 80 images...\n",
      "searching...\n",
      "Downloading 3 images...\n",
      "searching...\n",
      "Downloading 80 images...\n",
      "searching...\n",
      "Downloading 80 images...\n",
      "searching...\n",
      "Downloading 80 images...\n"
     ]
    }
   ],
   "source": [
    "# Run function for list of searches.\n",
    "for search in searches:\n",
    "    if __name__ == '__main__':\n",
    "        main(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code modified from [source](https://python.plainenglish.io/how-to-automatically-download-bulk-images-for-your-dataset-using-python-f1efffba7a03)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Next Steps\n",
    "\n",
    "After downloading the google images, I manually sorted them into two folders, \"bear_scat\" and \"anything_but\" deleting images that seemed not useful (ie. cartoon, drawings,images full of text, bad quality images). I ended up with a total of 1048 images to use for my models, which I create in the next section.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
